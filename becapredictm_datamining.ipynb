{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importamos librerias necesarias\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('datapronabeclimpio.csv', 'r') as csvfile:\n",
    "    becarios_reader = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    # Importamos el dataset como array de numpy\n",
    "    becarios_dataset = np.array([ row for row in becarios_reader])   #becarios_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['' 'convocatoria' 'region' ..., 'institucionsede' 'carreradescripcion'\n",
      "  'genero']\n",
      " ['0' 'Beca 18 Modalidad Ordinaria 2012' 'LIMA' ..., 'SEDE LIMA'\n",
      "  'INGENIERIA GEOLOGICA' 'MASCULINO']\n",
      " ['1' 'Beca 18 Modalidad Ordinaria 2012' 'LIMA' ..., 'SEDE LIMA'\n",
      "  'INGENIERIA GEOGRAFICA' 'MASCULINO']\n",
      " ..., \n",
      " ['15185'\n",
      "  'Beca para Poblaciones Vulnerables y en Situaciones Especiales de FormaciÃ³n TÃ©cnico Productiva 2015'\n",
      "  'CAJAMARCA' ..., 'SEDE CAJAMARCA' 'PANADERIA' 'FEMENINO']\n",
      " ['15186'\n",
      "  'Beca para Poblaciones Vulnerables y en Situaciones Especiales de FormaciÃ³n TÃ©cnico Productiva 2015'\n",
      "  'CAJAMARCA' ..., 'SEDE CAJAMARCA' 'PANADERIA' 'FEMENINO']\n",
      " ['15188' 'Beca 18 Ordinaria 2015' 'LAMBAYEQUE' ..., 'SEDE CHICLAYO'\n",
      "  'ADMINISTRACION TURISTICA' 'FEMENINO']]\n"
     ]
    }
   ],
   "source": [
    "print(becarios_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'convocatoria' 'region' 'motivo' 'resolucion_ret_beca'\n",
      " 'fec_resolucion_ret_beca' 'fec_Postulacion' 'tipoinstitucion'\n",
      " 'institucioneducativa' 'institucionsede' 'carreradescripcion' 'genero']\n"
     ]
    }
   ],
   "source": [
    "# La primera fila tiene los nombres de los atributos\n",
    "feature_names = becarios_dataset[0]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' 'Beca 18 Modalidad Ordinaria 2012' 'LIMA' '1' 'RESOLUCION JEFATURAL'\n",
      " '2014-11' '2012-04' 'Universidad' 'NACIONAL MAYOR DE SAN MARCOS'\n",
      " 'SEDE LIMA' 'INGENIERIA GEOLOGICA' 'MASCULINO']\n"
     ]
    }
   ],
   "source": [
    "#vemos la primera tupla del dataset\n",
    "print (becarios_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...,  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "# En la columna 3 tenemos la clase que queremos predecir (es decir, el motivo por el cual perdieron la beca)\n",
    "# Vale 1 si desaprobo, 0 si abandonó. \n",
    "becarios_y=becarios_dataset[1:,3].astype(float)\n",
    "print(becarios_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['LIMA', 'Universidad', 'MASCULINO'], ['LIMA', 'Universidad', 'MASCULINO'], ['LIMA', 'Universidad', 'MASCULINO'], ['LIMA', 'Universidad', 'MASCULINO'], ['LIMA', 'Universidad', 'MASCULINO']]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las columnas con las cuales vamos a trabajar:\n",
    "# 2: region\n",
    "# 7: tipoinstitucion\n",
    "# 11: genero\n",
    "becarios_x = becarios_dataset[1:, [2, 7, 11]]\n",
    "\n",
    "print(becarios_x[5:10].tolist())\n",
    "print(becarios_y[5:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase Genero: ['FEMENINO' 'MASCULINO']\n",
      "['LIMA', 'Universidad', '1'] 1.0\n"
     ]
    }
   ],
   "source": [
    "# Para trabajar con la libreria sklearn debemos convertir nuestras variables categoricas a numericas\n",
    "# Para ello utiizaremos los siguientes metodos: LabelEncoder y OneHotEncoder para realizar esta tarea.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "\n",
    "# Le paso los valores que tengo y el asigna un entero a cada clase posible\n",
    "# GENERO : MASCULINO,FENENINO los cambios por 1,0\n",
    "label_encoder = enc.fit(becarios_x[:, 2])\n",
    "print(\"Clase Genero:\", label_encoder.classes_)\n",
    "\n",
    "# usamos transform para transformar las clases por los números 0,1\n",
    "tranform = label_encoder.transform(becarios_x[:, 2])\n",
    "becarios_x[:, 2] = tranform\n",
    "print (becarios_x[1].tolist(), becarios_y[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Universidad', '1', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '1.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0', '0.0']\n"
     ]
    }
   ],
   "source": [
    "# Para transformar variables categorias que tienen mas de 2 posibles valores usamos OneHotEncoder\n",
    "\n",
    "# PARA TRANSFORMAR LA COLUMNA REGION\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder   \n",
    "lencoder = LabelEncoder()\n",
    "label_encoder = lencoder.fit(becarios_x[:,0])  #Ajuste el codificador de etiquetas\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_).reshape(31,1) # especificamos el nro de posibles valores\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "one_hot_encoder=enc.fit(integer_classes)\n",
    "\n",
    "# Primero, convierta clases a 0- (N-1) enteros usando el codificador label_encoder\n",
    "num_of_rows = becarios_x.shape[0]\n",
    "t = label_encoder.transform(becarios_x[:, 0]).reshape(num_of_rows, 1)\n",
    "\n",
    "# En segundo lugar, cree una matriz dispersa con tres columnas, cada una indicando si la instancia pertenece a la clase\n",
    "new_features = one_hot_encoder.transform(t)\n",
    "\n",
    "# Añadir las nuevas features a becarios_y\n",
    "becarios_x = np.concatenate([becarios_x, new_features.toarray()], axis = 1)\n",
    "\n",
    "#Eliminar columnas convertidas\n",
    "becarios_x = np.delete(becarios_x, [0], 1)\n",
    "\n",
    "# Actualizar los nombre de las features\n",
    "feature_names = ['tipoinstitucion','genero','LIMA','JUNIN','LORETO','PIURA',\n",
    "                 'LA LIBERTAD','CUSCO','AREQUIPA','PUNO','LAMBAYEQUE','AYACUCHO',\n",
    "                 'SAN MARTIN','CAJAMARCA','PASCO','HUANCAVELICA','TACNA','APURIMAC',\n",
    "                 'AMAZONAS','ANCASH','UCAYALI','ICA','HUANUCO','MOQUEGUA','CALLAO','MADRE DE DIOS',\n",
    "                'TUMBES','CUBA','HONDURAS','ESPAÃ‘A','FRANCIA','ARGENTINA','BRASIL']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convertir a valores numéricos\n",
    "#becarios_x = becarios_x.astype(float)\n",
    "\n",
    "print (becarios_x[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# PARA TRANSFORMAR LA COLUMNA TIPO INSTITUCION\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "lencoder = LabelEncoder()\n",
    "label_encoder = lencoder.fit(becarios_x[:,0])\n",
    "integer_classes = label_encoder.transform(label_encoder.classes_).reshape(8,1)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "one_hot_encoder=enc.fit(integer_classes)\n",
    "\n",
    "# Primero, convierta clases a 0- (N-1) enteros usando el codificador label_encoder\n",
    "num_of_rows = becarios_x.shape[0]\n",
    "t = label_encoder.transform(becarios_x[:, 0]).reshape(num_of_rows, 1)\n",
    "\n",
    "# En segundo lugar, cree una matriz dispersa con tres columnas, cada una indicando si la instancia pertenece a la clase\n",
    "new_features = one_hot_encoder.transform(t)\n",
    "\n",
    "# Añadir las nuevas features a becarios_y\n",
    "becarios_x = np.concatenate([becarios_x, new_features.toarray()], axis = 1)\n",
    "\n",
    "#Eliminar columnas convertidas\n",
    "becarios_x = np.delete(becarios_x, [0], 1)\n",
    "\n",
    "# Actualizar los nombre de las features\n",
    "feature_names = ['genero','LIMA','JUNIN','LORETO','PIURA',\n",
    "                 'LA LIBERTAD','CUSCO','AREQUIPA','PUNO','LAMBAYEQUE','AYACUCHO',\n",
    "                 'SAN MARTIN','CAJAMARCA','PASCO','HUANCAVELICA','TACNA','APURIMAC',\n",
    "                 'AMAZONAS','ANCASH','UCAYALI','ICA','HUANUCO','MOQUEGUA','CALLAO','MADRE DE DIOS',\n",
    "                'TUMBES','CUBA','HONDURAS','ESPAÑA','FRANCIA','ARGENTINA','BRASIL',\n",
    "                 'INSTITUTO DE EDUCACION SUPERIOR TECNOLOGICO',\n",
    "                 'UNIVERSIDAD','Centro de Educación Técnico-Productiva',\n",
    "                'Instituto de Educación Superior Pedagógico','Instituto de Idiomas',\n",
    "                'Instituto','Instituto de Educación Superior','Academia Pre-Universitaria']\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Convertir a valores numéricos\n",
    "becarios_x = becarios_x.astype(float) # Transformamos a float \n",
    "\n",
    "print (becarios_x[100].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de las nuevas features: ['genero', 'LIMA', 'JUNIN', 'LORETO', 'PIURA', 'LA LIBERTAD', 'CUSCO', 'AREQUIPA', 'PUNO', 'LAMBAYEQUE', 'AYACUCHO', 'SAN MARTIN', 'CAJAMARCA', 'PASCO', 'HUANCAVELICA', 'TACNA', 'APURIMAC', 'AMAZONAS', 'ANCASH', 'UCAYALI', 'ICA', 'HUANUCO', 'MOQUEGUA', 'CALLAO', 'MADRE DE DIOS', 'TUMBES', 'CUBA', 'HONDURAS', 'ESPAÑA', 'FRANCIA', 'ARGENTINA', 'BRASIL', 'INSTITUTO DE EDUCACION SUPERIOR TECNOLOGICO', 'UNIVERSIDAD', 'Centro de Educación Técnico-Productiva', 'Instituto de Educación Superior Pedagógico', 'Instituto de Idiomas', 'Instituto', 'Instituto de Educación Superior', 'Academia Pre-Universitaria']\n",
      "Valores: [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.]\n",
      "Target(motivo de pérdida): 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Nombre de las nuevas features:',feature_names)\n",
    "print('Valores:',becarios_x[0])\n",
    "print('Target(motivo de pérdida):', becarios_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## HASTA AQUI YA TENENEMOS NUESTROS DATOS LIMPIOS Y PREPROCESADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## El proceso de aprendizaje aplicaremos arbol de decision.\n",
    "## Vamos primero separar el dataset en dos:\n",
    "## un conjunto de entrenamiento y otro de testeo. \n",
    "##  Trabajaremos siempre sobre el de entrenamiento,\n",
    "##  y dejamos el de testeo para evaluar nuestros resultados. Lo dividimos en 75/25\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(becarios_x, becarios_y, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Usaremos el modelo DecisionTreeClassifier del Arbol de decision\n",
    "\n",
    "from sklearn import tree\n",
    "classifier = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3,min_samples_leaf=5)\n",
    "classifier = classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.645 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.74      0.67      2326\n",
      "        1.0       0.70      0.55      0.62      2504\n",
      "\n",
      "avg / total       0.66      0.64      0.64      4830\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[1732  594]\n",
      " [1121 1383]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def measure_performance(X,y,classifier, show_accuracy=True, show_classification_report=True, show_confusion_matrix=True):\n",
    "    y_pred=classifier.predict(X)   \n",
    "    if show_accuracy:\n",
    "        print(\"Accuracy:{0:.3f}\".format(metrics.accuracy_score(y,y_pred)),\"\\n\")\n",
    "\n",
    "    if show_classification_report:\n",
    "        print(\"Classification report\")\n",
    "        print(metrics.classification_report(y,y_pred),\"\\n\")\n",
    "        \n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion matrix\")\n",
    "        print(metrics.confusion_matrix(y,y_pred),\"\\n\")\n",
    "        \n",
    "measure_performance(X_train,y_train,classifier, show_classification_report=True, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.646 \n",
      "\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.63      0.73      0.68       819\n",
      "        1.0       0.67      0.56      0.61       792\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1611\n",
      " \n",
      "\n",
      "Confusion matrix\n",
      "[[595 224]\n",
      " [347 445]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "measure_performance(X_test,y_test, classifier, show_classification_report=True, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6443203   0.64285714  0.63704164]\n",
      "0.641406360526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(classifier, X_train, y_train)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
